# @package _global_
training:
  max_epochs: 50
  learning_rate: 1e-3
  
  # Configuración del optimizador
  optimizer:
    name: "Adam"
    weight_decay: 0.0
    
  # Configuración del scheduler
  scheduler:
    name: "ReduceLROnPlateau"
    mode: "min"
    factor: 0.5
    patience: 5
    min_lr: 1e-7
    
  # Configuración de early stopping
  early_stopping:
    monitor: "val_loss"
    patience: 10
    mode: "min"
    
  # Configuración específica de PyTorch Lightning
  lightning:
    accelerator: "auto"
    devices: "auto"
    precision: "16-mixed"
    gradient_clip_val: 1.0
    accumulate_grad_batches: 1
    
  # Configuración de validación
  validation:
    check_val_every_n_epoch: 1
    val_check_interval: 1.0 